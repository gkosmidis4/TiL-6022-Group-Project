{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5398320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done! Saved as 'data/DelftTravelData.csv'\n",
      "                                  City  Mean_Distance_to_Delft  \\\n",
      "Amsterdam Centraal  Amsterdam Centraal                   70.48   \n",
      "Rotterdam Centraal  Rotterdam Centraal                   12.54   \n",
      "Den Haag Centraal    Den Haag Centraal                   13.74   \n",
      "Utrecht Centraal      Utrecht Centraal                   65.67   \n",
      "Eindhoven Centraal  Eindhoven Centraal                  127.36   \n",
      "\n",
      "                    Mean_Time_to_Delft  \n",
      "Amsterdam Centraal                  59  \n",
      "Rotterdam Centraal                  19  \n",
      "Den Haag Centraal                   17  \n",
      "Utrecht Centraal                    53  \n",
      "Eindhoven Centraal                 102  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "distance = pd.read_csv(\"../data/CarDistance_matrix.csv\", index_col=0)\n",
    "time = pd.read_csv(\"../data/CarTime_matrix.csv\", index_col=0)\n",
    "\n",
    "ref_city = \"TU Delft Campus\"\n",
    "\n",
    "to_delft_dist = distance[ref_city]\n",
    "from_delft_dist = distance.loc[ref_city]\n",
    "\n",
    "time_to_delft = time[ref_city]\n",
    "time_from_delft = time.loc[ref_city]\n",
    "\n",
    "mean_distance = (to_delft_dist + from_delft_dist) / 2\n",
    "mean_time_seconds = (time_to_delft + time_from_delft) / 2\n",
    "\n",
    "mean_time_minutes = np.ceil(mean_time_seconds / 60)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"City\": distance.index,\n",
    "    \"Mean_Distance_to_Delft\": mean_distance.round(2),\n",
    "    \"Mean_Time_to_Delft\": mean_time_minutes.astype(int)\n",
    "})\n",
    "\n",
    "df = df[df[\"City\"] != ref_city]\n",
    "\n",
    "df.to_csv(\"../data/DelfttravelData.csv\", index=False)\n",
    "\n",
    "print(\"✅ Done! Saved as 'data/DelftTravelData.csv'\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28638600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved ../data/DelftTravelData_withCosts.csv\n",
      "⚠️ Cities missing one or more costs: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# --- Paths (adjust the first line if your file has a capital 'T') ---\n",
    "delft_path = \"../data/DelfttravelData.csv\"\n",
    "costs_path = \"../data/RoadTaxes_InsuranceCity_ParkingPermitCity.csv\"\n",
    "out_path   = \"../data/DelftTravelData_withCosts.csv\"\n",
    "\n",
    "# --- Load Delft base (the table you want to enrich) ---\n",
    "delft = pd.read_csv(delft_path)   # expects columns: City, Mean_Distance_to_Delft, Mean_Time_to_Delft\n",
    "\n",
    "# --- Load Costs (semicolon-separated; decimals look '.' in your screenshot) ---\n",
    "costs = (\n",
    "    pd.read_csv(costs_path, sep=\";\", engine=\"python\")\n",
    "      .dropna(how=\"all\", axis=0)\n",
    "      .dropna(how=\"all\", axis=1)\n",
    ")\n",
    "\n",
    "# --- Identify column names in costs robustly ---\n",
    "def find_col(cols, keywords, default_idx=None):\n",
    "    for c in cols:\n",
    "        cl = c.lower()\n",
    "        if any(k in cl for k in keywords):\n",
    "            return c\n",
    "    if default_idx is not None and default_idx < len(cols):\n",
    "        return cols[default_idx]\n",
    "    return None\n",
    "\n",
    "city_costs_col = find_col(costs.columns, [\"city\"], default_idx=0)\n",
    "roadtax_col    = find_col(costs.columns, [\"roadtax\", \"roadtaxes\", \"motor\", \"belasting\"], default_idx=1)\n",
    "ins_col        = find_col(costs.columns, [\"insurance\", \"verzek\"], default_idx=2)\n",
    "parking_col    = find_col(costs.columns, [\"parking\", \"permit\", \"parkeer\", \"vergunning\"], default_idx=3)\n",
    "\n",
    "rename_map = {}\n",
    "if city_costs_col: rename_map[city_costs_col] = \"City_costs\"\n",
    "if roadtax_col:    rename_map[roadtax_col]    = \"Roadtax_eur_per_month\"\n",
    "if ins_col:        rename_map[ins_col]        = \"Insurance_eur_per_month\"\n",
    "if parking_col:    rename_map[parking_col]    = \"ParkingPermit_eur_per_month\"\n",
    "\n",
    "costs = costs.rename(columns=rename_map)\n",
    "\n",
    "# --- Clean city names for matching ---\n",
    "def clean_city(s: pd.Series) -> pd.Series:\n",
    "    s = s.astype(str).str.lower().str.strip()\n",
    "    s = s.str.replace(r\"\\b(centraal|central|centrum|station)\\b\", \"\", regex=True)  # remove suffixes\n",
    "    s = s.str.replace(r\"^gemeente\\s+\", \"\", regex=True)                             # drop 'gemeente' prefix\n",
    "    s = s.str.replace(r\"[’'`]\", \"\", regex=True)                                    # normalize quotes\n",
    "    s = s.str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "    return s\n",
    "\n",
    "manual_map = {\n",
    "    # add special cases here if needed, e.g.:\n",
    "    # \"s hertogenbosch\": \"den bosch\",\n",
    "    # \"the hague\": \"den haag\",  # if the other file uses English\n",
    "}\n",
    "\n",
    "def apply_map(s: pd.Series) -> pd.Series:\n",
    "    return s.replace(manual_map)\n",
    "\n",
    "delft[\"City_clean\"] = apply_map(clean_city(delft[\"City\"]))\n",
    "costs[\"City_clean\"] = apply_map(clean_city(costs[\"City_costs\"]))\n",
    "\n",
    "# De-duplicate costs by cleaned name to avoid row multiplication\n",
    "costs = costs.drop_duplicates(subset=\"City_clean\", keep=\"first\")\n",
    "\n",
    "# --- Select only the columns we want to bring over ---\n",
    "bring = [\"City_clean\"]\n",
    "for c in [\"Roadtax_eur_per_month\", \"Insurance_eur_per_month\", \"ParkingPermit_eur_per_month\"]:\n",
    "    if c in costs.columns: bring.append(c)\n",
    "\n",
    "# --- Merge (LEFT) and tidy ---\n",
    "merged = delft.merge(costs[bring], on=\"City_clean\", how=\"left\").drop(columns=[\"City_clean\"])\n",
    "\n",
    "# Ensure numeric types (if any are strings)\n",
    "for col in [\"Roadtax_eur_per_month\", \"Insurance_eur_per_month\", \"ParkingPermit_eur_per_month\"]:\n",
    "    if col in merged.columns:\n",
    "        merged[col] = pd.to_numeric(merged[col], errors=\"coerce\")\n",
    "\n",
    "# Order columns nicely\n",
    "front = [\"City\", \"Mean_Distance_to_Delft\", \"Mean_Time_to_Delft\"]\n",
    "cost_cols = [c for c in [\"Roadtax_eur_per_month\", \"Insurance_eur_per_month\", \"ParkingPermit_eur_per_month\"] if c in merged.columns]\n",
    "others = [c for c in merged.columns if c not in front + cost_cols]\n",
    "merged = merged[front + cost_cols + others]\n",
    "\n",
    "# --- Save ---\n",
    "merged.to_csv(out_path, index=False)\n",
    "print(f\"✅ Saved {out_path}\")\n",
    "\n",
    "# --- Report any cities that missed a match (so you can add to manual_map if needed) ---\n",
    "missing = merged.loc[\n",
    "    merged[cost_cols].isna().any(axis=1) if cost_cols else [False]*len(merged),\n",
    "    \"City\"\n",
    "].unique()\n",
    "print(\"⚠️ Cities missing one or more costs:\", missing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1925ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current folder: c:\\Users\\maira\\Desktop\\TiL-6022-Group-Project\\code\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"current folder:\", os.getcwd())\n",
    "print(os.path.exists(\"../data/Pompprijzen_motorbrandstoffen_brandstofsoort_per_dag_06102025_122232.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ee29467",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/Pompprijzen_motorbrandstoffen_brandstofsoort_per_dag_06102025_122232.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# The file has:\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# 0: title line\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# 1: empty line (\"\"), \u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# 4: '\"Perioden\";\"euro/liter\";\"euro/liter\";\"euro/liter\"'\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Data starts at line 5 → so skiprows=5 and provide column names ourselves.\u001b[39;00m\n\u001b[32m     15\u001b[39m names = [\u001b[33m\"\u001b[39m\u001b[33mPerioden\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mBenzine Euro95\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mDiesel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mLpg\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpython\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\n\u001b[32m     25\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Drop footer like \"Bron: ...\"\u001b[39;00m\n\u001b[32m     28\u001b[39m df = df[df[\u001b[33m\"\u001b[39m\u001b[33mPerioden\u001b[39m\u001b[33m\"\u001b[39m].str.contains(\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\\\u001b[39m\u001b[33md\u001b[39m\u001b[38;5;132;01m{4}\u001b[39;00m\u001b[33m\"\u001b[39m, na=\u001b[38;5;28;01mFalse\u001b[39;00m)]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maira\\anaconda3\\envs\\TIL6022-25\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maira\\anaconda3\\envs\\TIL6022-25\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maira\\anaconda3\\envs\\TIL6022-25\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maira\\anaconda3\\envs\\TIL6022-25\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maira\\anaconda3\\envs\\TIL6022-25\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../data/Pompprijzen_motorbrandstoffen_brandstofsoort_per_dag_06102025_122232.csv'"
     ]
    }
   ],
   "source": [
    "#FILTERING THE PUMP PRICE DATA AND RETURNING 1 AVERAGE PRICE FOR SEPTEMBER 2024\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# --- FILE PATH ---\n",
    "path = \"../data/Pompprijzen_motorbrandstoffen_brandstofsoort_per_dag_06102025_122232.csv\"\n",
    "\n",
    "# The file has:\n",
    "# 0: title line\n",
    "# 1: empty line (\"\"), \n",
    "# 2: '\"\";\"Onderwerp\"'\n",
    "# 3: '\"\";\"Benzine Euro95\";\"Diesel\";\"Lpg\"'\n",
    "# 4: '\"Perioden\";\"euro/liter\";\"euro/liter\";\"euro/liter\"'\n",
    "# Data starts at line 5 → so skiprows=5 and provide column names ourselves.\n",
    "names = [\"Perioden\", \"Benzine Euro95\", \"Diesel\", \"Lpg\"]\n",
    "\n",
    "df = pd.read_csv(\n",
    "    path,\n",
    "    sep=\";\",\n",
    "    quotechar='\"',\n",
    "    skiprows=5,\n",
    "    names=names,\n",
    "    engine=\"python\",\n",
    "    dtype=str\n",
    ")\n",
    "\n",
    "# Drop footer like \"Bron: ...\"\n",
    "df = df[df[\"Perioden\"].str.contains(r\"\\d{4}\", na=False)]\n",
    "\n",
    "# Convert European comma decimals to floats\n",
    "for col in [\"Benzine Euro95\", \"Diesel\", \"Lpg\"]:\n",
    "    df[col] = df[col].str.replace(\",\", \".\", regex=False).astype(float)\n",
    "\n",
    "# ----- CHOOSE THE FUEL TO AVERAGE -----\n",
    "fuel_col = \"Benzine Euro95\"   # change to \"Diesel\" or \"Lpg\" if you prefer\n",
    "\n",
    "# Compute monthly average (one value)\n",
    "monthly_avg = round(df[fuel_col].mean(), 3)\n",
    "\n",
    "# Save as a 1x1 CSV (same style as before)\n",
    "out = pd.DataFrame([[monthly_avg]], columns=[f\"{fuel_col} (€/L)\"], index=[\"Monthly Average\"])\n",
    "out.to_csv(\"../data/Avg_PumpPrice_Monthly.csv\")\n",
    "\n",
    "print(\"✅ Saved: ../data/Avg_PumpPrice_Monthly.csv\")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9074e471",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TIL6022-25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
